\documentclass[11pt,a4paper]{article}

\usepackage{hyperref}
\usepackage{amsmath}
\usepackage{bm}
\usepackage{enumerate}
\usepackage{pdfpages}
\usepackage{wrapfig}
\usepackage{course}

% \setmonofont{Tahoma}
\settextfont{XB Niloofar}
\setlatintextfont{Linux Libertine}

\begin{document}
\سربرگ{دکتر مهدی جعفری سیاوشانی}{بهینه‌سازی محدب}{بهار ۹۹}{}{\bf پروژه}{تاریخ سررسید: ۱۳۹۹/۰۴/۳۱}
\vspace{0.3cm}
برای حل این تمرین می‌توانید از کتاب‌خانه‌هایی که دارای امکان 
\lr{automatic differentiation}
هستند مانند PyTorch و jax استفاده کنید. در آخر موارد خواسته شده در هر بخش را به صورت یک گزارش به همراه کدهای خود فشرده و آپلود کنید.
\section*{روش‌های درجه دو}
% در این بخش به بررسی روش‌های درجه دو برای بهینه‌سازی محدب می‌پردازیم.

می‌خواهیم مسالهٔ دسته بندی به کمک 
\lr{logistic regression} را برای داده‌های ساخته‌شده  بررسی کنیم.

داده‌ها را به این صورت تولید می‌کنیم:
\begin{itemize}
\item
دستهٔ صفر: صد داده از توزیع:
$\mathcal{N}(
\begin{bmatrix} 
-1\\
-1\\
\end{bmatrix}, I)$
\item
دستهٔ یک: صد داده از توزیع:
$\mathcal{N}(
\begin{bmatrix} 
1\\
1\\
\end{bmatrix}, I)$
\end{itemize}
سپس داده‌ها را به صورت تصادفی مخلوط می‌کنیم و ۱۵۰ نقطهٔ اول را به عنوان دادهٔ آموزش و ۵۰ نقطهٔ دیگر را برای ارزیابی جدا می‌کنیم. برای سادگی پیاده‌سازی \lr{logistic regression} حالت بدون intercept آن را در نظر می‌گیریم یعنی:
\begin{align}
&X: \text{\lr{input features with shape (M, 2)}}\\
&y: \text{\lr{target labels with shape (M, 1)}}\\
&w = \begin{bmatrix} 
w_1\\
w_2\\
\end{bmatrix}\\
&\hat{y} = \sigma(Xw)\\
&loss = \frac{-1}{M} [y^T log(\hat{y}) + (1 - y)^Tlog(1 - \hat{y})]
\end{align}
که در آن $\sigma$ تابع سیگموید است. در هر بخش بعد از بهینه‌سازی روی دادهٔ آموزش میزان دقت روی دادهٔ ارزیابی را هم گزارش کنید.
\begin{enumerate}
\item
دربارهٔ محدب بودن تابع هزینه نسبت به بردار پارامترها ($w$) بحث کنید.
\item
نمودار سطح تابع هزینه را برای مقادیر 
$-2 < w_1 < 2 , -2 < w_2 < 2$
رسم کنید.
\item
با شروع از 
$w_s = \begin{bmatrix} 
0\\
0\\
\end{bmatrix}$
روش 
\lr{gradient descent}
را با 
\lr{learning rate}
$\lambda = 0.2$
برای پنج گام اجرا کنید.
\item
با شروع از $w_s$ این بار روش \lr{Newton} را برای پنج گام اجرا کنید.
\item
روش 
\lr{Natural Gradient}
یک روش بهینه‌سازی از خانوادهٔ 
\lr{steepest descent}
است که در آن نرم استفاده شده، فاصلهٔ KL توزیع likelihood بین دو بردار پارامتر است. دربارهٔ این روش مطالعه کنید و به این سوال‌ها پاسخ دهید:
\begin{enumerate}
\item
منظور از فضای توزیع
\lr{(distribution space)}
در این روش چیست؟
\item
رابطهٔ این روش با 
\lr{Fisher Information Matrix}
چیست؟
\end{enumerate}
\item
با شروع از $w_s$ روش 
\lr{Natural Gradient}
را با پارامتر یادگیری 
$\alpha = 0.2$
و با استفاده از 
\lr{Emperical Fisher Information Matrix}
پیاده‌سازی کنید و برای پنج گام اجرا کنید. عملیات به روزرسانی به صورت:
\begin{align*}
w_{next} = w - \alpha F^{-1}\nabla_{w}loss(w)
\end{align*}
خواهد بود.
\item
حال می‌خواهیم میزان حساس بودن روش‌های بالا را به تغییرات در فضای پارامترها بررسی کنیم. برای این کار رابطهٔ ۴ را به صورت زیر تغییر می‌دهیم:
\begin{align*}
\hat{y} = \sigma(0.01 \times Xw)
\end{align*}
پس از این تغییر دوباره نمودار سطح تابع هزینه را برای مقادیر 
$-2 < w_1 < 2 , -2 < w_2 < 2$
رسم کنید.
\item
روش 
\lr{Gradient Descent}
را با 
\lr{learning rate}
$\lambda = 0.2$
برای پنج گام برای روابط جدید اجرا کنید. در یک نمودار تغییرات loss این حالت را به همراه تغییرات loss قسمت ۴ رسم کنید و مقایسه کنید.
\item
روش 
\lr{Newton}
را برای پنج گام برای روابط جدید اجرا کنید. در یک نمودار تغییرات loss این حالت را به همراه تغییرات loss قسمت ۵ رسم کنید و مقایسه کنید.
\item
روش 
\lr{Natural Gradient}
را با پارامتر یادگیری 
$\alpha = 0.2$
برای پنج گام برای روابط جدید اجرا کنید. در یک نمودار تغییرات loss این حالت را به همراه تغییرا loss قسمت ۶ رسم کنید و مقایسه کنید.
\item
نتایج بخش‌های ۸ و ۹ و ۱۰ را توضیح دهید. در هر حالت چرا این مشاهده حاصل شد؟
\item
در روش 
\lr{Natural Gradient}
در هر گام توزیع likelihood را برای قبل و بعد از به‌روز کردن پارامترها در یک نمودار رسم کنید.
\item
مزایا و معایب این سه روش را بررسی کنید. در بهینه‌سازی شبکه‌های عصبی برای این که مزیت‌های روش‌های درجه دو را داشته باشیم ولی معایب آن‌ها را نداشته باشیم از چه روش‌هایی استفاده می‌شود؟
\end{enumerate}
\section*{روش‌های کاهش واریانس}
می‌خواهیم مسالهٔ دسته‌بندی چندکلاسه به کمک 
\lr{multiclass logistic regression}
به همراه 
\lr{L2 Regularization}
 برای ارقام دادگان MNIST بررسی کنیم.
 
 برای کم‌شدن زمان اجرا 
$M=6000$
  نمونهٔ تصادفی از دادگان آموزش انتخاب می‌کنیم و به عنوان دادهٔ آموزش استفاده می‌کنیم. برای ارزیابی هم از داده‌های ارزیابی استفاده می‌کنیم. روابط این مساله برای یک دستهٔ k تایی به این صورت است:
\begin{align*}
&X: \text{\lr{input features with shape (k, 28*28)}}\\
&y: \text{\lr{target labels with shape (k, )}}\\
&W: \text{\lr{ with shape (28*28, 10)}}\\
&b: \text{\lr{ with shape (10, )}}\\
&\hat{y} = softmax(XW + b)\\
&loss = \frac{-1}{k} \sum_{i = 1}^{k}log(\hat{y}[i, y[i]]) + \frac{1}{2}\gamma (trace(W^TW) + b^Tb)
\end{align*}
که در آن $\gamma$ ضریب regularization است که به صورت
$\gamma = 10^{-4}$
به آن مقدار می‌دهیم.
\begin{enumerate}
\item
روش SGD خام
\lr{(batch\_size = 1)}
 را برای 
$t = M * 100$
قدم با 
\lr{learning rate}
های
$\lambda = \{0.01, 0.05\}$
اجرا کنید. پس از هر $M$ قدم loss روی کل دادگان آموزش، دقت روی دادهٔ ارزیابی، و اندازهٔ واریانس قدم‌های برداشته شدهٔ آن $M$ قدم را محاسبه کنید (جمع واریانس بعدها).
نمودار تغییرات این سه پارامتر را رسم کنید. برای نمودار تغییرات واریانس از نمودار نیمه‌لگاریتمی استفاده کنید.
\item
روش 
\lr{mini-batch SGD}
با
\lr{(batch\_size = 4)}
 را برای 
$t = \frac{M}{4} * 100$
قدم با 
\lr{learning rate}
های
$\lambda = \{0.01, 0.04, 0.2\}$
اجرا کنید. پس از هر 
$\frac{M}{4}$
قدم، loss روی کل دادگان آموزش، دقت روی دادهٔ ارزیابی، و اندازهٔ واریانس قدم‌های برداشته شدهٔ آن 
$\frac{M}{4}$
قدم را محاسبه کنید.
نمودار تغییرات loss ، دقت، و واریانس را به همراه تغییرات مربوط به بخش قبل رسم کنید و مقایسه کنید.
\item
یکی از روش‌های کاهش واریانس روش 
SVRG\footnote{\lr{Stochastic Variance Reduced Gradient} \href{https://papers.nips.cc/paper/4937-accelerating-stochastic-gradient-descent-using-predictive-variance-reduction.pdf}{مقاله}}
است. این روش را مطالعه کنید و به سوالات زیر پاسخ دهید:
\begin{enumerate}
\item
مقدار 
$\mathbb{E}[w^{(t)} | w^{(t - 1)}]$
را حساب کنید. این مقدار چه رابطه‌ای با روش SGD دارد؟
\item
با توجه به مشاهدهٔ بخش (آ) چه انتظاری از نمودار تغییرات loss برای SGD و SVRG با نرخ یادگیری یکسان داریم؟
\item
SVRG چرا باعث کاهش واریانس می‌شود؟
\end{enumerate}
\item
روش 
SVRG
 را با
 \lr{learning rate}
های
$\lambda = \{0.01, 0.05\}$
اجرا کنید. متغیر $m$ که در الگوریتم باید مشخص شود را به صورت
$m = M$
مقداردهی کنید. همین‌طور می‌توانید به انتخاب خودتان از 
\lr{option I}
یا 
\lr{option II}
استفاده کنید. پس از هر بار اجرا شدن حلقهٔ داخلی مقدار loss روی کل دادگان آموزش، دقت روی دادهٔ ارزیابی، و اندازهٔ واریانس قدم‌های برداشته شده را محاسبه کنید. نمودار تغییرات این سه پارامتر را به همراه نمودارهای بخش‌های قبلی ترسیم و مقایسه کنید.
\item
مزیت‌ها و معایب روش SVRG چیست؟
\item
زیاد و کم کردن مقدار m چه تفاوت‌هایی در عملکرد الگوریتم ایجاد می‌کند؟
\end{enumerate}
\begin{flushleft}
سلامت باشید
\end{flushleft}
\end{document}